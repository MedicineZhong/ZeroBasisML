{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # 导入NumPy\nimport pandas as pd # 导入Pandas\ndf_train = pd.read_csv('../input/new-earth/exoTrain.csv') # 导入训练集\ndf_test = pd.read_csv('../input/new-earth/exoTest.csv') # 导入测试集\nprint(df_train.head()) # 输入头几行数据\nprint(df_train.info()) # 输出训练集信息","execution_count":1,"outputs":[{"output_type":"stream","text":"   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n\n    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n\n   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n0      48.57      92.54      39.32      61.42       5.08     -39.54  \n1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n\n[5 rows x 3198 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5087 entries, 0 to 5086\nColumns: 3198 entries, LABEL to FLUX.3197\ndtypes: float64(3197), int64(1)\nmemory usage: 124.1 MB\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle # 导入乱序工具\ndf_train = shuffle(df_train) # 乱序训练集\ndf_test = shuffle(df_test)  # 乱序测试集","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train.iloc[:, 1:].values # 构建特征集（训练）\ny_train = df_train.iloc[:, 0].values # 构建标签集（训练）\nX_test = df_test.iloc[:, 1:].values # 构建特征集（测试）\ny_test = df_test.iloc[:, 0].values # 构建标签集（测试）\ny_train = y_train - 1 # 标签转换成惯用的(0，1)分类\ny_test = y_test - 1 # 标签转换成惯用的(0，1)分类\nprint (X_train) # 打印训练集中的特征\nprint (y_train) # 打印训练集中的标签","execution_count":3,"outputs":[{"output_type":"stream","text":"[[ 4.97000e+00  5.98000e+00  7.95000e+00 ...  1.64000e+00 -3.01000e+00\n   1.77000e+00]\n [ 2.12900e+01  3.01800e+01  3.39500e+01 ... -4.67200e+01 -3.84700e+01\n  -2.03200e+01]\n [-1.82180e+02 -1.62970e+02 -1.66720e+02 ...  2.77040e+02  2.56200e+02\n   2.40700e+02]\n ...\n [-2.46400e+01 -2.52000e+01 -1.42300e+01 ... -1.26000e+00 -1.74000e+00\n   6.22000e+00]\n [ 6.57500e+01  5.99200e+01  5.75100e+01 ...  2.24700e+01  2.45800e+01\n   1.95500e+01]\n [ 1.51076e+03  1.33869e+03  1.31544e+03 ...  5.61320e+02  5.89190e+02\n   5.44000e+02]]\n[0 0 0 ... 0 0 0]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.expand_dims(X_train, axis=2) # 张量升阶，以满足序列数据集的要求\nX_test = np.expand_dims(X_test, axis=2) # 张量升阶，以满足序列数据集的要求","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential # 导入序贯模型\nfrom keras import layers # 导入所有类型的层\nfrom keras.optimizers import Adam # 导入优化器\nmodel = Sequential() # 序贯模型\nmodel.add(layers.Conv1D(32, kernel_size=10, strides=4,\n          input_shape=(3197, 1))) # 1D CNN层\nmodel.add(layers.MaxPooling1D(pool_size=4, strides=2)) # 池化层\nmodel.add(layers.GRU(256, return_sequences=True)) # 关键，GRU层够要大\nmodel.add(layers.Flatten()) # 展平\nmodel.add(layers.Dropout(0.5)) # Dropout层\nmodel.add(layers.BatchNormalization()) # 批标准化   \nmodel.add(layers.Dense(1, activation='sigmoid')) # 分类输出层\nopt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\nmodel.compile(optimizer=opt, # 优化器\n              loss = 'binary_crossentropy', # 交叉熵\n              metrics=['accuracy']) # 准确率","execution_count":5,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X_train,y_train, # 训练集\n                    validation_split = 0.2, # 部分训练集数据拆分成验证集\n                    batch_size = 128, # 批量大小\n                    epochs = 4, # 训练轮次\n                    shuffle = True) # 乱序","execution_count":6,"outputs":[{"output_type":"stream","text":"Train on 4069 samples, validate on 1018 samples\nEpoch 1/4\n4069/4069 [==============================] - 20s 5ms/step - loss: 0.6591 - accuracy: 0.6601 - val_loss: 0.3451 - val_accuracy: 0.9578\nEpoch 2/4\n4069/4069 [==============================] - 17s 4ms/step - loss: 0.3586 - accuracy: 0.8685 - val_loss: 0.1894 - val_accuracy: 0.9921\nEpoch 3/4\n4069/4069 [==============================] - 15s 4ms/step - loss: 0.2314 - accuracy: 0.9356 - val_loss: 0.1251 - val_accuracy: 0.9921\nEpoch 4/4\n4069/4069 [==============================] - 15s 4ms/step - loss: 0.1664 - accuracy: 0.9666 - val_loss: 0.0960 - val_accuracy: 0.9931\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report # 分类报告\nfrom sklearn.metrics import confusion_matrix # 混淆矩阵\ny_prob = model.predict(X_test) # 对测试集进行预测\ny_pred =  np.where(y_prob > 0.5, 1, 0) #将概率值转换成真值\ncm = confusion_matrix(y_pred, y_test)\nprint('Confusion matrix:\\n', cm, '\\n')\nprint(classification_report(y_pred, y_test))","execution_count":7,"outputs":[{"output_type":"stream","text":"Confusion matrix:\n [[565   5]\n [  0   0]] \n\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      1.00       570\n           1       0.00      0.00      0.00         0\n\n    accuracy                           0.99       570\n   macro avg       0.50      0.50      0.50       570\nweighted avg       1.00      0.99      1.00       570\n\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(len(y_prob)):\n#      if y_prob[i] >= 0.5: \n#         y_pred[i] = 1\n#      else:\n#         y_pred[i] = 0","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred =  np.where(y_prob > 0.15, 1, 0) # 进行阈值调整\ncm = confusion_matrix(y_pred, y_test) \nprint('Confusion matrix:\\n', cm, '\\n')\nprint(classification_report(y_pred, y_test))","execution_count":13,"outputs":[{"output_type":"stream","text":"Confusion matrix:\n [[556   4]\n [  9   1]] \n\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99       560\n           1       0.20      0.10      0.13        10\n\n    accuracy                           0.98       570\n   macro avg       0.59      0.55      0.56       570\nweighted avg       0.97      0.98      0.97       570\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**下面是两个函数式API的构建代码段，请读者自行研究如何使用函数式API建构更灵活的模型。**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers # 导入各种层\nfrom keras.models import Model # 导入模型\nfrom keras.optimizers import Adam # 导入Adam优化器\ninput = layers.Input(shape=(3197, 1)) # Input\n# 通过函数式API构建模型\nx = layers.Conv1D(32, kernel_size=10, strides=4)(input)\nx = layers.MaxPooling1D(pool_size=4, strides=2)(x)\nx = layers.GRU(256, return_sequences=True)(x)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.5)(x)\nx = layers.BatchNormalization()(x)\noutput = layers.Dense(1, activation='sigmoid')(x) # Output\nmodel = Model(input, output) \nmodel.summary() # 显示模型的输出\nopt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01) # 设置优化器\nmodel.compile(optimizer=opt, # 优化器\n              loss = 'binary_crossentropy', # 交叉熵\n              metrics=['accuracy']) # 准确率","execution_count":10,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 3197, 1)           0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 797, 32)           352       \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 397, 32)           0         \n_________________________________________________________________\ngru_2 (GRU)                  (None, 397, 256)          221952    \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 101632)            0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 101632)            0         \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 101632)            406528    \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 101633    \n=================================================================\nTotal params: 730,465\nTrainable params: 527,201\nNon-trainable params: 203,264\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 构建正向网络\ninput_1 = layers.Input(shape=(3197, 1))\nx = layers.GRU(32, return_sequences=True)(input_1)\nx = layers.Flatten()(x)\nx = layers.Dropout(0.5)(x)\n# 构建逆向网络\ninput_2 = layers.Input(shape=(3197, 1))\ny = layers.GRU(32, return_sequences=True)(input_2)\ny = layers.Flatten()(y)\ny = layers.Dropout(0.5)(y)\n# 连接两个网络\nz = layers.concatenate([x, y])\noutput = layers.Dense(1, activation='sigmoid')(z)\nmodel = Model([input_1,input_2], output)\nmodel.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 3197, 1)      0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 3197, 1)      0                                            \n__________________________________________________________________________________________________\ngru_3 (GRU)                     (None, 3197, 32)     3264        input_2[0][0]                    \n__________________________________________________________________________________________________\ngru_4 (GRU)                     (None, 3197, 32)     3264        input_3[0][0]                    \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 102304)       0           gru_3[0][0]                      \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 102304)       0           gru_4[0][0]                      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 102304)       0           flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 102304)       0           flatten_4[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 204608)       0           dropout_3[0][0]                  \n                                                                 dropout_4[0][0]                  \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 1)            204609      concatenate_1[0][0]              \n==================================================================================================\nTotal params: 211,137\nTrainable params: 211,137\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}